{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "############################ Try SGLang and Test Llama3 on MATH  ###################################\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'execute_shell_command' from 'sglang.utils' (/data/irving/llm-reasoners/examples/ScalableTreeSearch/sglang/python/sglang/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msglang\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     execute_shell_command,\n\u001b[1;32m      3\u001b[0m     wait_for_server,\n\u001b[1;32m      4\u001b[0m     terminate_process,\n\u001b[1;32m      5\u001b[0m     print_highlight,\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'execute_shell_command' from 'sglang.utils' (/data/irving/llm-reasoners/examples/ScalableTreeSearch/sglang/python/sglang/utils.py)"
     ]
    }
   ],
   "source": [
    "from sglang.utils import (\n",
    "    execute_shell_command,\n",
    "    wait_for_server,\n",
    "    terminate_process,\n",
    "    print_highlight,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' anyoneałyны JahreFailedmagFri CG Nepani биponse州бург stayed rapport', 'meta_info': {'prompt_tokens': 10, 'completion_tokens': 16, 'completion_tokens_wo_jump_forward': 16, 'id': '071c76b5d7cf4f499ae6424c7e5dc4fe'}, 'scores': [], 'forward_only': False}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '81d0d0a774e74e739ebc52f61905b455', 'object': 'chat.completion', 'created': 1732166824, 'model': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Here are 3 countries and their capitals:\\n\\n1. Country: Japan\\n   Capital: Tokyo\\n\\n2. Country: Brazil\\n   Capital: Brasília\\n\\n3. Country: Australia\\n   Capital: Canberra'}, 'logprobs': None, 'finish_reason': 'stop', 'matched_stop': 128009}], 'usage': {'prompt_tokens': 43, 'total_tokens': 86, 'completion_tokens': 43, 'prompt_tokens_details': None}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "url = \"http://localhost:10086/v1/chat/completions\"\n",
    "\n",
    "data = {\n",
    "    \"model\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"List 3 countries and their capitals.\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='a46fd10e002f4b9883bf347c8081639f', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Here are 3 countries and their capitals:\\n\\n1. Country: Japan\\n   Capital: Tokyo\\n\\n2. Country: Australia\\n   Capital: Canberra\\n\\n3. Country: Brazil\\n   Capital: Brasília', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), matched_stop=128009)], created=1732166827, model='meta-llama/Meta-Llama-3.1-8B-Instruct', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=43, prompt_tokens=48, total_tokens=91, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.Client(base_url=\"http://127.0.0.1:10086/v1\", api_key=\"None\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "        {\"role\": \"user\", \"content\": \"List 3 countries and their capitals.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=128,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load math500-test.jsonl\n",
    "# import json\n",
    "\n",
    "# data = []\n",
    "# with open(\"math500-test.jsonl\", \"r\") as f:\n",
    "#     raw_data = f.readlines()\n",
    "\n",
    "# for line in raw_data:\n",
    "#     data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/irving/anaconda3/envs/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/data/irving/anaconda3/envs/myenv/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "2024-11-20 20:58:40,563\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "# Need to import an evaluator from dart_math\n",
    "# to compare math expressions with ground truth answers\n",
    "\n",
    "from dart_math.eval import EvaluatorMath\n",
    "math_evaluator = EvaluatorMath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from simple_eval by OpenAI\n",
    "\n",
    "import random\n",
    "import re\n",
    "from typing import Literal\n",
    "\n",
    "import blobfile as bf\n",
    "import pandas\n",
    "\n",
    "import common\n",
    "from common import ANSWER_PATTERN, HTML_JINJA, check_equality\n",
    "from eval_types import Eval, EvalResult, SamplerBase, SingleEvalResult\n",
    "\n",
    "QUERY_TEMPLATE = \"\"\"\n",
    "Solve the following math problem step by step. The last line of your response should be of the form Answer: $ANSWER (without quotes) where $ANSWER is the answer to the problem.\n",
    "\n",
    "{Question}\n",
    "\n",
    "Remember to put your answer on its own line after \"Answer:\", and you do not need to use a \\\\boxed command.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "class MathEval(Eval):\n",
    "    def __init__(\n",
    "        self,\n",
    "        equality_checker: SamplerBase,\n",
    "        num_examples: int | None = None,\n",
    "        n_repeats: int = 1,\n",
    "        split: Literal[\"math_test\", \"math_500_test\"] = \"my_math_500_test\",  # see readme.md\n",
    "    ):\n",
    "        df = pandas.read_csv(\n",
    "            # bf.BlobFile(f\"https://openaipublic.blob.core.windows.net/simple-evals/{split}.csv\")\n",
    "            bf.BlobFile(f\"{split}.csv\")\n",
    "        )\n",
    "        examples = [row.to_dict() for _, row in df.iterrows()]\n",
    "        if num_examples:\n",
    "            assert n_repeats == 1, \"n_repeats only supported for num_examples = None\"\n",
    "            rng = random.Random(0)\n",
    "            examples = rng.sample(examples, num_examples)\n",
    "        self.examples = examples * n_repeats\n",
    "        self.equality_checker = equality_checker\n",
    "\n",
    "    def __call__(self, sampler: SamplerBase) -> EvalResult:\n",
    "        def fn(row: dict):\n",
    "            prompt_messages = [\n",
    "                sampler._pack_message(content=QUERY_TEMPLATE.format(**row), role=\"user\")\n",
    "            ]\n",
    "            response_text = sampler(prompt_messages)\n",
    "            match = re.search(ANSWER_PATTERN, response_text)\n",
    "            extracted_answer = match.group(1) if match else None\n",
    "            # score = 0 if extracted_answer is None else \\\n",
    "            #     float(check_equality(self.equality_checker, row[\"Answer\"], extracted_answer))\n",
    "            score = 0 if extracted_answer is None else math_evaluator.eq(row[\"Answer\"], extracted_answer)\n",
    "            \n",
    "            # my change: none -> error\n",
    "            html = common.jinja_env.from_string(HTML_JINJA).render(\n",
    "                prompt_messages=prompt_messages,\n",
    "                next_message=dict(content=response_text, role=\"assistant\"),\n",
    "                score=score,\n",
    "                correct_answer=row[\"Answer\"],\n",
    "                extracted_answer=extracted_answer,\n",
    "            )\n",
    "            convo = prompt_messages + [dict(content=response_text, role=\"assistant\")]\n",
    "            return SingleEvalResult(html=html, score=score, convo=convo)\n",
    "\n",
    "        results = common.map_with_progress(fn, self.examples)\n",
    "        return common.aggregate_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also from simple_eval by OpenAI\n",
    "\n",
    "import base64\n",
    "import time\n",
    "from typing import Any\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from eval_types import MessageList, SamplerBase\n",
    "\n",
    "OPENAI_SYSTEM_MESSAGE_API = \"You are a helpful assistant.\"\n",
    "OPENAI_SYSTEM_MESSAGE_CHATGPT = (\n",
    "    \"You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture.\"\n",
    "    + \"\\nKnowledge cutoff: 2023-12\\nCurrent date: 2024-04-01\"\n",
    ")\n",
    "\n",
    "\n",
    "class ChatCompletionSampler(SamplerBase):\n",
    "    \"\"\"\n",
    "    Sample from OpenAI's chat completion API\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: str = \"gpt-3.5-turbo\",\n",
    "        system_message: str | None = None,\n",
    "        temperature: float = 0.5,\n",
    "        max_tokens: int = 1024,\n",
    "        client = None, \n",
    "        return_full_response: bool = False,\n",
    "    ):\n",
    "        self.api_key_name = \"OPENAI_API_KEY\"\n",
    "        self.client = client or OpenAI()\n",
    "        # using api_key=os.environ.get(\"OPENAI_API_KEY\")  # please set your API_KEY\n",
    "        self.model = model\n",
    "        self.system_message = system_message\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.image_format = \"url\"\n",
    "        self.return_full_response = return_full_response\n",
    "\n",
    "    def _handle_image(\n",
    "        self, image: str, encoding: str = \"base64\", format: str = \"png\", fovea: int = 768\n",
    "    ):\n",
    "        new_image = {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/{format};{encoding},{image}\",\n",
    "            },\n",
    "        }\n",
    "        return new_image\n",
    "\n",
    "    def _handle_text(self, text: str):\n",
    "        return {\"type\": \"text\", \"text\": text}\n",
    "\n",
    "    def _pack_message(self, role: str, content: Any):\n",
    "        return {\"role\": str(role), \"content\": content}\n",
    "\n",
    "    def __call__(self, message_list: MessageList) -> str:\n",
    "        if self.system_message:\n",
    "            message_list = [self._pack_message(\"system\", self.system_message)] + message_list\n",
    "        trial = 0\n",
    "        # print(message_list)\n",
    "        while True:\n",
    "            try:\n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=message_list,\n",
    "                    temperature=self.temperature,\n",
    "                    max_tokens=self.max_tokens,\n",
    "                )\n",
    "                if self.return_full_response:\n",
    "                    print(\"message\", message_list, \"response\", response.choices[0].message.content)\n",
    "                    return response.choices[0].message.content\n",
    "                else:\n",
    "                    return response.choices[0].message.content\n",
    "\n",
    "            # NOTE: BadRequestError is triggered once for MMMU, please uncomment if you are reruning MMMU\n",
    "            except openai.BadRequestError as e:\n",
    "                print(\"Bad Request Error\", e)\n",
    "                return \"\"\n",
    "            except Exception as e:\n",
    "                exception_backoff = 2**trial  # expontial back off\n",
    "                print(\n",
    "                    f\"Rate limit exception so wait and retry {trial} after {exception_backoff} sec\",\n",
    "                    e,\n",
    "                )\n",
    "                time.sleep(exception_backoff)\n",
    "                trial += 1\n",
    "            # unknown error shall throw exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our sglang client as OpenAI client\n",
    "client = openai.Client(base_url=\"http://127.0.0.1:10086/v1\", api_key=\"None\")\n",
    "\n",
    "sampler = ChatCompletionSampler(model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "                                temperature=0.0,\n",
    "                                max_tokens=2048,\n",
    "                                client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MathEval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m debug \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# equality_checker = sampler\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m matheval \u001b[38;5;241m=\u001b[39m MathEval(\n\u001b[1;32m      4\u001b[0m      equality_checker\u001b[38;5;241m=\u001b[39msampler, num_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m debug \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m500\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MathEval' is not defined"
     ]
    }
   ],
   "source": [
    "debug = False\n",
    "# equality_checker = sampler\n",
    "matheval = MathEval(\n",
    "     equality_checker=sampler, num_examples=10 if debug else 500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplers = {\"llama3\": sampler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matheval': <__main__.MathEval object at 0x7f41f836ab90>}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 373/500 [02:15<00:46,  2.75it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "{'pred': [ValueError(\"could not convert string to float: 'A\\\\\\\\begin{array}-13\\\\\\\\3\\\\\\\\4\\\\\\\\end{array}=\\\\\\\\begin{array}-2\\\\\\\\-14\\\\\\\\-13\\\\\\\\end{array}'\"), SyntaxError('unexpected character after line continuation character', ('<string>', 1, 15, \"Symbol ('A' )\\\\Symbol ('begin' ){Symbol ('array' )}-Integer (13 )\\\\Integer (3 )\\\\Integer (4 )\\\\Symbol ('end' ){Symbol ('array' )}=\\\\Symbol ('begin' ){Symbol ('array' )}-Integer (2 )\\\\-Integer (14 )\\\\-Integer (13 )\\\\Symbol ('end' ){Symbol ('array' )}\", 1, 0)), ValueError('Invalid interval: A\\\\begin{array}-13\\\\3\\\\4\\\\end{array}=\\\\begin{array}-2\\\\-14\\\\-13\\\\end{array}'), LaTeXParsingError('I expected something else here\\nend{array}=\\n~~~~~~~~~~~^'), LaTeXParsingError(\"I don't understand this\\nA\\\\begin{array}-13\\\\3\\\\4\\\\end{array}=\\\\begin{array}-2\\\\-14\\\\-13\\\\end{array}\\n~~~~~~~~~~~~~~~~~^\")]}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sampler_name, sampler \u001b[38;5;129;01min\u001b[39;00m samplers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m eval_name, eval_obj \u001b[38;5;129;01min\u001b[39;00m evals\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 14\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43meval_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# ^^^ how to use a sampler\u001b[39;00m\n\u001b[1;32m     16\u001b[0m         file_stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampler_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[8], line 66\u001b[0m, in \u001b[0;36mMathEval.__call__\u001b[0;34m(self, sampler)\u001b[0m\n\u001b[1;32m     63\u001b[0m     convo \u001b[38;5;241m=\u001b[39m prompt_messages \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mdict\u001b[39m(content\u001b[38;5;241m=\u001b[39mresponse_text, role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SingleEvalResult(html\u001b[38;5;241m=\u001b[39mhtml, score\u001b[38;5;241m=\u001b[39mscore, convo\u001b[38;5;241m=\u001b[39mconvo)\n\u001b[0;32m---> 66\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcommon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_with_progress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m common\u001b[38;5;241m.\u001b[39maggregate_results(results)\n",
      "File \u001b[0;32m/data/irving/llm-reasoners/examples/ScalableTreeSearch/common.py:212\u001b[0m, in \u001b[0;36mmap_with_progress\u001b[0;34m(f, xs, num_threads)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ThreadPool(\u001b[38;5;28mmin\u001b[39m(num_threads, \u001b[38;5;28mlen\u001b[39m(xs))) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m--> 212\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/irving/anaconda3/envs/myenv/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/data/irving/anaconda3/envs/myenv/lib/python3.10/multiprocessing/pool.py:873\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m--> 873\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "File \u001b[0;32m/data/irving/anaconda3/envs/myenv/lib/python3.10/multiprocessing/pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    123\u001b[0m job, i, func, args, kwds \u001b[38;5;241m=\u001b[39m task\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap_exception \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _helper_reraises_exception:\n",
      "Cell \u001b[0;32mIn[8], line 53\u001b[0m, in \u001b[0;36mMathEval.__call__.<locals>.fn\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     50\u001b[0m extracted_answer \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# score = 0 if extracted_answer is None else \\\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#     float(check_equality(self.equality_checker, row[\"Answer\"], extracted_answer))\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extracted_answer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mmath_evaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAnswer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextracted_answer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# my change: none -> error\u001b[39;00m\n\u001b[1;32m     56\u001b[0m html \u001b[38;5;241m=\u001b[39m common\u001b[38;5;241m.\u001b[39mjinja_env\u001b[38;5;241m.\u001b[39mfrom_string(HTML_JINJA)\u001b[38;5;241m.\u001b[39mrender(\n\u001b[1;32m     57\u001b[0m     prompt_messages\u001b[38;5;241m=\u001b[39mprompt_messages,\n\u001b[1;32m     58\u001b[0m     next_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(content\u001b[38;5;241m=\u001b[39mresponse_text, role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m     extracted_answer\u001b[38;5;241m=\u001b[39mextracted_answer,\n\u001b[1;32m     62\u001b[0m )\n",
      "File \u001b[0;32m/data/irving/llm-reasoners/examples/ScalableTreeSearch/dart_math/eval.py:970\u001b[0m, in \u001b[0;36mEvaluatorMath.eq\u001b[0;34m(self, ref, pred, compare_sets)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;66;03m# print(expr_parse_errs)\u001b[39;00m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(expr_parse_errs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 970\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(expr_parse_errs)\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: {'pred': [ValueError(\"could not convert string to float: 'A\\\\\\\\begin{array}-13\\\\\\\\3\\\\\\\\4\\\\\\\\end{array}=\\\\\\\\begin{array}-2\\\\\\\\-14\\\\\\\\-13\\\\\\\\end{array}'\"), SyntaxError('unexpected character after line continuation character', ('<string>', 1, 15, \"Symbol ('A' )\\\\Symbol ('begin' ){Symbol ('array' )}-Integer (13 )\\\\Integer (3 )\\\\Integer (4 )\\\\Symbol ('end' ){Symbol ('array' )}=\\\\Symbol ('begin' ){Symbol ('array' )}-Integer (2 )\\\\-Integer (14 )\\\\-Integer (13 )\\\\Symbol ('end' ){Symbol ('array' )}\", 1, 0)), ValueError('Invalid interval: A\\\\begin{array}-13\\\\3\\\\4\\\\end{array}=\\\\begin{array}-2\\\\-14\\\\-13\\\\end{array}'), LaTeXParsingError('I expected something else here\\nend{array}=\\n~~~~~~~~~~~^'), LaTeXParsingError(\"I don't understand this\\nA\\\\begin{array}-13\\\\3\\\\4\\\\end{array}=\\\\begin{array}-2\\\\-14\\\\-13\\\\end{array}\\n~~~~~~~~~~~~~~~~~^\")]}"
     ]
    }
   ],
   "source": [
    "# also from simple_eval by OpenAI\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "evals = {\n",
    "    \"matheval\": matheval\n",
    "}\n",
    "print(evals)\n",
    "debug_suffix = \"_DEBUG\" if debug else \"\"\n",
    "print(debug_suffix)\n",
    "mergekey2resultpath = {}\n",
    "for sampler_name, sampler in samplers.items():\n",
    "    for eval_name, eval_obj in evals.items():\n",
    "        result = eval_obj(sampler)\n",
    "        # ^^^ how to use a sampler\n",
    "        file_stem = f\"{eval_name}_{sampler_name}\"\n",
    "        report_filename = f\"/tmp/{file_stem}{debug_suffix}.html\"\n",
    "        print(f\"Writing report to {report_filename}\")\n",
    "        with open(report_filename, \"w\") as fh:\n",
    "            fh.write(common.make_report(result))\n",
    "        metrics = result.metrics | {\"score\": result.score}\n",
    "        print(metrics)\n",
    "        result_filename = f\"/tmp/{file_stem}{debug_suffix}.json\"\n",
    "        with open(result_filename, \"w\") as f:\n",
    "            f.write(json.dumps(metrics, indent=2))\n",
    "        print(f\"Writing results to {result_filename}\")\n",
    "        mergekey2resultpath[f\"{file_stem}\"] = result_filename\n",
    "merge_metrics = []\n",
    "for eval_sampler_name, result_filename in mergekey2resultpath.items():\n",
    "    try:\n",
    "        result = json.load(open(result_filename, \"r+\"))\n",
    "    except Exception as e:\n",
    "        print(e, result_filename)\n",
    "        continue\n",
    "    result = result.get(\"f1_score\", result.get(\"score\", None))\n",
    "    eval_name = eval_sampler_name[: eval_sampler_name.find(\"_\")]\n",
    "    sampler_name = eval_sampler_name[eval_sampler_name.find(\"_\") + 1 :]\n",
    "    merge_metrics.append(\n",
    "        {\"eval_name\": eval_name, \"sampler_name\": sampler_name, \"metric\": result}\n",
    "    )\n",
    "merge_metrics_df = pd.DataFrame(merge_metrics).pivot(\n",
    "    index=[\"sampler_name\"], columns=\"eval_name\"\n",
    ")\n",
    "print(\"\\nAll results: \")\n",
    "print(merge_metrics_df.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "###################################### SGLang for Tree Search ######################################\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "from typing import Literal\n",
    "\n",
    "import blobfile as bf\n",
    "import pandas\n",
    "\n",
    "import common\n",
    "from common import ANSWER_PATTERN, HTML_JINJA, check_equality\n",
    "from eval_types import Eval, EvalResult, SamplerBase, SingleEvalResult\n",
    "\n",
    "split = \"my_math_500_test\"\n",
    "df = pandas.read_csv(\n",
    "    # bf.BlobFile(f\"https://openaipublic.blob.core.windows.net/simple-evals/{split}.csv\")\n",
    "    bf.BlobFile(f\"{split}.csv\")\n",
    ")\n",
    "examples = [row.to_dict() for _, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## try to use sglang to sequentially generate next steps.\n",
    "\n",
    "import sglang as sgl\n",
    "import argparse\n",
    "from sglang.test.test_utils import (\n",
    "    add_common_sglang_args_and_parse,\n",
    "    select_sglang_backend,\n",
    ")\n",
    "import time\n",
    "\n",
    "max_steps = 30\n",
    "\n",
    "\n",
    "@sgl.function\n",
    "def search_try(s, question):\n",
    "    s += sgl.user(\n",
    "        f\"\"\"Solve the following math problem step by step. Steps should be separated with two new lines. The last line of your response should be of the form Answer: $ANSWER (without quotes) where $ANSWER is the answer to the problem.\n",
    "        \n",
    "{question}\n",
    "\n",
    "Remember to separate steps with two new lines, and finally put your answer on its own line after \"Answer:\", and you do not need to use a \\\\boxed command.\n",
    "\"\"\"\n",
    "    )\n",
    "    \n",
    "    s += sgl.assistant_begin()\n",
    "    s += sgl.gen(max_tokens=256, stop=[\"\\n\\n\"])\n",
    "    \n",
    "    # print(f\"''{s.text()}''\")\n",
    "    \n",
    "    for _ in range(max_steps):\n",
    "        # s += new_line\n",
    "        s += \"\\n\\n\"\n",
    "        s += sgl.gen(max_tokens=256, stop=[\"\\n\\n\"])\n",
    "        # print(f\"''{s.text()}''\")  \n",
    "        if \"Answer:\" in s.text().split(\"\\n\")[-1]:\n",
    "            break\n",
    "    \n",
    "    # s += sgl.assistant(sgl.gen(\"step\", max_tokens=256, temperature=0.3, stop=[\"\\n\\n\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    # data_path=\"sglang/benchmark/tree_of_thought_v0/test.jsonl\",\n",
    "    # num_questions=2,\n",
    "    port=10086,\n",
    "    parallel=16,\n",
    "    backend='srt',\n",
    "    host=\"http://127.0.0.1\",\n",
    "    result_file=\"results.txt\"\n",
    ")\n",
    "\n",
    "# q = \"\"\"If $x^3$ is a positive factor of $10!,$ how many possible integer values of $x$ are there?  (Reminder: For a positive integer $n$, the expression $n!$ stands for the product of the integers from 1 up to (and including) $n$.)\"\"\"\n",
    "\n",
    "arguments = [{\"question\": d['Question']} for d in examples[:100]]\n",
    "\n",
    "# Select backend\n",
    "backend = select_sglang_backend(args)\n",
    "\n",
    "# # Run requests\n",
    "# tic = time.time()\n",
    "# states = search_try.run_batch(\n",
    "#     arguments,\n",
    "#     temperature=0,\n",
    "#     backend=backend,\n",
    "#     num_threads=args.parallel,\n",
    "#     progress_bar=True,\n",
    "# )\n",
    "# latency = time.time() - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/irving/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "2024-11-22 23:14:54,959\tINFO util.py:154 -- Outdated packages:\n",
      "  ipywidgets==7.8.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from dart_math.eval import EvaluatorMath\n",
    "math_evaluator = EvaluatorMath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'states' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# for i, state in enumerate(states):\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#     print(f\"Question: {arguments[i]['question']}\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     print(f\"Answer: {state.text()}\")\u001b[39;00m\n\u001b[1;32m      5\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, state \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(states):\n\u001b[1;32m      7\u001b[0m     response_text \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mtext()\n\u001b[1;32m      8\u001b[0m     match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(ANSWER_PATTERN, response_text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'states' is not defined"
     ]
    }
   ],
   "source": [
    "# for i, state in enumerate(states):\n",
    "#     print(f\"Question: {arguments[i]['question']}\")\n",
    "#     print(f\"Answer: {state.text()}\")\n",
    "\n",
    "scores = 0\n",
    "for i, state in enumerate(states):\n",
    "    response_text = state.text()\n",
    "    match = re.search(ANSWER_PATTERN, response_text.split(\"\\n\")[-1])\n",
    "    extracted_answer = match.group(1) if match else None\n",
    "    # score = 0 if extracted_answer is None else \\\n",
    "    #     float(check_equality(self.equality_checker, row[\"Answer\"], extracted_answer))\n",
    "    answer = examples[i][\"Answer\"]\n",
    "    score = 0 if extracted_answer is None else math_evaluator.eq(answer, extracted_answer)\n",
    "    \n",
    "    print(f\"{extracted_answer} || {answer} || {score}\")\n",
    "    scores += score\n",
    "    \n",
    "print(scores/len(states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try beam search\n",
    "\n",
    "import sglang as sgl\n",
    "from sglang import RuntimeEndpoint, function, gen\n",
    "max_steps = 30\n",
    "\n",
    "BEAM_SIZE = 4\n",
    "BEAM_WIDTH = 2\n",
    "assert BEAM_SIZE % BEAM_WIDTH == 0\n",
    "\n",
    "@sgl.function\n",
    "def beam_search(s, question):\n",
    "    s += sgl.user(\n",
    "        f\"\"\"Solve the following math problem step by step. Steps should be separated with two new lines. The last line of your response should be of the form Answer: $ANSWER (without quotes) where $ANSWER is the answer to the problem.\n",
    "        \n",
    "{question}\n",
    "\n",
    "Remember to separate steps with two new lines, and finally put your answer on its own line after \"Answer:\", and you do not need to use a \\\\boxed command.\"\"\"\n",
    "    )\n",
    "\n",
    "    s += sgl.assistant_begin()\n",
    "    forks = s.fork(BEAM_SIZE)\n",
    "    forks += sgl.gen(max_tokens=256, stop=[\"\\n\\n\"], temperature=0.5)\n",
    "    step = s.text().split(\"\\n\\n\")[-1]\n",
    "\n",
    "    # print(f\"''{s.text()}''\")\n",
    "    cur_states = list(forks)\n",
    "    \n",
    "    answer_states = []\n",
    "\n",
    "    for _ in range(max_steps):\n",
    "        \n",
    "        # s += new_line\n",
    "        # randomly select BEAM_WIDTH states\n",
    "        # print(\"--A--\")\n",
    "        \n",
    "        cur_beam_width = min(BEAM_WIDTH, len(cur_states))\n",
    "        \n",
    "        cur_states = random.sample(cur_states, cur_beam_width)\n",
    "\n",
    "        # expand to BEAM_SIZE states\n",
    "        new_states = []\n",
    "\n",
    "        for state in cur_states:\n",
    "\n",
    "            # print(\"--B--\")\n",
    "\n",
    "            if \"Answer:\" in state.text().split(\"\\n\")[-1]:\n",
    "                answer_states.append(state)\n",
    "                continue\n",
    "            \n",
    "            # print(\"--C--\")\n",
    "            forked_states = state.fork((BEAM_SIZE - 1) // cur_beam_width + 1)\n",
    "            forked_states += \"\\n\\n\" + sgl.gen(max_tokens=256, stop=[\"\\n\\n\"], temperature=0.5)\n",
    "            new_states.extend(forked_states)\n",
    "        \n",
    "        # print(\"--D--\")\n",
    "        #print(len(new_states))\n",
    "        cur_states = new_states\n",
    "        \n",
    "        if len(answer_states) > 0:\n",
    "            break\n",
    "            \n",
    "        \n",
    "    return answer_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]Exception in thread Thread-22 (_thread_worker_func):\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/site-packages/sglang/lang/interpreter.py\", line 323, in _thread_worker_func\n",
      "    self._execute(expr)\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/site-packages/sglang/lang/interpreter.py\", line 342, in _execute\n",
      "    self._execute_gen(other)\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/site-packages/sglang/lang/interpreter.py\", line 462, in _execute_gen\n",
      "    comp, meta_info = self.backend.generate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/site-packages/sglang/backend/runtime_endpoint.py\", line 124, in generate\n",
      "Exception in thread Thread-23 (_thread_worker_func):\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/threading.py\", line 1010, in run\n",
      "Exception in thread Thread-24 (_thread_worker_func):\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    res = http_request(\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/site-packages/sglang/utils.py\", line 113, in http_request\n",
      "    self.run()\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/site-packages/sglang/lang/interpreter.py\", line 323, in _thread_worker_func\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/site-packages/sglang/lang/interpreter.py\", line 323, in _thread_worker_func\n",
      "Exception in thread Thread-21 (_thread_worker_func):\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self._execute(expr)\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/site-packages/sglang/lang/interpreter.py\", line 342, in _execute\n",
      "    self.run()\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/threading.py\", line 1010, in run\n",
      "    resp = urllib.request.urlopen(req, data=data, cafile=verify)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 215, in urlopen\n",
      "    self._execute_gen(other)\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/site-packages/sglang/lang/interpreter.py\", line 462, in _execute_gen\n",
      "    return opener.open(url, data, timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 521, in open\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/site-packages/sglang/lang/interpreter.py\", line 323, in _thread_worker_func\n",
      "    self._execute(expr)\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/site-packages/sglang/lang/interpreter.py\", line 342, in _execute\n",
      "    response = meth(req, response)\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 630, in http_response\n",
      "    comp, meta_info = self.backend.generate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/site-packages/sglang/backend/runtime_endpoint.py\", line 124, in generate\n",
      "    response = self.parent.error(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 559, in error\n",
      "    res = http_request(\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/site-packages/sglang/utils.py\", line 113, in http_request\n",
      "    self._execute(expr)\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/site-packages/sglang/lang/interpreter.py\", line 342, in _execute\n",
      "    self._execute_gen(other)\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/site-packages/sglang/lang/interpreter.py\", line 462, in _execute_gen\n",
      "    resp = urllib.request.urlopen(req, data=data, cafile=verify)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 215, in urlopen\n",
      "    return self._call_chain(*args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 492, in _call_chain\n",
      "    comp, meta_info = self.backend.generate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/site-packages/sglang/backend/runtime_endpoint.py\", line 124, in generate\n",
      "    return opener.open(url, data, timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 521, in open\n",
      "    self._execute_gen(other)\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/site-packages/sglang/lang/interpreter.py\", line 462, in _execute_gen\n",
      "    result = func(*args)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 639, in http_error_default\n",
      "    res = http_request(\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/site-packages/sglang/utils.py\", line 113, in http_request\n",
      "    response = meth(req, response)\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 630, in http_response\n",
      "    resp = urllib.request.urlopen(req, data=data, cafile=verify)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 215, in urlopen\n",
      "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "urllib.error.HTTPError: HTTP Error 500: Internal Server Error\n",
      "    return opener.open(url, data, timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 521, in open\n",
      "    response = meth(req, response)\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 630, in http_response\n",
      "    response = self.parent.error(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 559, in error\n",
      "    comp, meta_info = self.backend.generate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/site-packages/sglang/backend/runtime_endpoint.py\", line 124, in generate\n",
      "    return self._call_chain(*args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 492, in _call_chain\n",
      "    response = self.parent.error(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 559, in error\n",
      "    res = http_request(\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/site-packages/sglang/utils.py\", line 113, in http_request\n",
      "    result = func(*args)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 639, in http_error_default\n",
      "    return self._call_chain(*args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 492, in _call_chain\n",
      "    resp = urllib.request.urlopen(req, data=data, cafile=verify)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 215, in urlopen\n",
      "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "urllib.error.HTTPError: HTTP Error 500: Internal Server Error\n",
      "    return opener.open(url, data, timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 521, in open\n",
      "    result = func(*args)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 639, in http_error_default\n",
      "    response = meth(req, response)\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 630, in http_response\n",
      "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "urllib.error.HTTPError: HTTP Error 500: Internal Server Error\n",
      "    response = self.parent.error(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 559, in error\n",
      "    return self._call_chain(*args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 492, in _call_chain\n",
      "    result = func(*args)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/data/irving/anaconda3/lib/python3.12/urllib/request.py\", line 639, in http_error_default\n",
      "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "urllib.error.HTTPError: HTTP Error 500: Internal Server Error\n"
     ]
    }
   ],
   "source": [
    "bs_states = beam_search.run_batch(\n",
    "    arguments[:1],\n",
    "    temperature=0,\n",
    "    backend=backend,\n",
    "    num_threads=args.parallel,\n",
    "    progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,\\pi) ки || \\left( 3, \\frac{\\pi}{2} \\right) || False\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "scores = 0\n",
    "\n",
    "for i, states in enumerate(bs_states):\n",
    "    if len(states.ret_value) == 0:\n",
    "        continue\n",
    "\n",
    "    response_text = states.ret_value[0].text()\n",
    "    match = re.search(ANSWER_PATTERN, response_text.split(\"\\n\")[-1])\n",
    "    extracted_answer = match.group(1) if match else None\n",
    "    # score = 0 if extracted_answer is None else \\\n",
    "    #     float(check_equality(self.equality_checker, row[\"Answer\"], extracted_answer))\n",
    "    answer = examples[i][\"Answer\"]\n",
    "    score = 0 if extracted_answer is None else math_evaluator.eq(answer, extracted_answer)\n",
    "    \n",
    "    print(f\"{extracted_answer} || {answer} || {score}\")\n",
    "    scores += score\n",
    "\n",
    "print(scores/len(bs_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProgramState(<|start_header_id|>user<|end_header_id|>\n",
       "\n",
       "Solve the following math problem step by step. Steps should be separated with two new lines. The last line of your response should be of the form Answer: $ANSWER (without quotes) where $ANSWER is the answer to the problem.\n",
       "        \n",
       "Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\theta),$ where $r > 0$ and $0 \\le \\theta < 2 \\pi.$\n",
       "\n",
       "Remember to separate steps with two new lines, and finally put your answer on its own line after \"Answer:\", and you do not need to use a \\boxed command.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:48<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "arguments = [{\"question\": d['Question']} for d in examples[:100]]\n",
    "\n",
    "# Select backend\n",
    "backend = select_sglang_backend(args)\n",
    "\n",
    "# Run requests\n",
    "tic = time.time()\n",
    "states = search_try.run_batch(\n",
    "    arguments,\n",
    "    temperature=0,\n",
    "    backend=backend,\n",
    "    num_threads=args.parallel,\n",
    "    progress_bar=True,\n",
    ")\n",
    "latency = time.time() - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, \\frac{\\pi}{2}) || \\left( 3, \\frac{\\pi}{2} \\right) || True\n",
      "None || p - q || 0\n",
      "$\\frac{14}{3}$ || \\frac{14}{3} || True\n",
      "9 || 9 || True\n",
      "Angela || \\text{Evelyn} || False\n",
      "126 || 42 || False\n",
      "None || 27 || 0\n",
      "$20$ || 90^\\circ || False\n",
      "3√13 || 3\\sqrt{13} || False\n",
      "None || 4 || 0\n",
      "None || 2220 || 0\n",
      "125/168 || \\frac{3}{56} || False\n",
      "284 || 284 || True\n",
      "$5$ || 5 || True\n",
      "$10$ || \\sqrt{51} || False\n",
      "None || 6 - 5i || 0\n",
      "-50 || -50 || True\n",
      "$\\pi$ || \\pi || True\n",
      "112 || 28 || False\n",
      "None || 3 || 0\n",
      "6 + 9i || 6+9i || True\n",
      "None || 13535 || 0\n",
      "None || 5 || 0\n",
      "5 || x=5 || True\n",
      "10 || 10 || True\n",
      "$\\boxed{}$ || 1,-2 || False\n",
      "12 || 144 || False\n",
      "$78 || 78 || True\n",
      "-2 + 7i || -2 + 7i || True\n",
      "112 || 225 || False\n",
      "$2_8$ || 52_8 || False\n",
      "11$\\sqrt{2}$ || 11\\sqrt2 || True\n",
      "None || 720 || 0\n",
      "None || \\frac{243}{625} || 0\n",
      "$-\\frac{1}{32}$ || -125 || False\n",
      "3 || 3 || True\n",
      "$2, 5$ || 3, 5, 7 || False\n",
      "360 || 72 || False\n",
      "2000 || 2000 || True\n",
      "23 || 23 || True\n",
      "12 || 12 || True\n",
      "17 || 17 || True\n",
      "4 || 4 || True\n",
      "None || 70 \\sqrt{2} || 0\n",
      "1.25 || 1.25 || True\n",
      "2 || 2 || True\n",
      "12 || 6 || False\n",
      "5 || 5 || True\n",
      "3/2 || \\frac{3}{2} || True\n",
      "$65$ || 83 || False\n",
      "0.46\n"
     ]
    }
   ],
   "source": [
    "# for i, state in enumerate(states):\n",
    "#     print(f\"Question: {arguments[i]['question']}\")\n",
    "#     print(f\"Answer: {state.text()}\")\n",
    "\n",
    "scores = 0\n",
    "for i, state in enumerate(states):\n",
    "    response_text = state.text()\n",
    "    match = re.search(ANSWER_PATTERN, response_text.split(\"\\n\")[-1])\n",
    "    extracted_answer = match.group(1) if match else None\n",
    "    # score = 0 if extracted_answer is None else \\\n",
    "    #     float(check_equality(self.equality_checker, row[\"Answer\"], extracted_answer))\n",
    "    answer = examples[i][\"Answer\"]\n",
    "    score = 0 if extracted_answer is None else math_evaluator.eq(answer, extracted_answer)\n",
    "    \n",
    "    print(f\"{extracted_answer} || {answer} || {score}\")\n",
    "    scores += score\n",
    "    \n",
    "print(scores/len(states))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sgl-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
